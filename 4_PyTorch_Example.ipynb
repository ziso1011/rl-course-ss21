{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pabair/rl-course-ws2020/blob/main/4_PyTorch_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOBUyiZq3d2u"
   },
   "source": [
    "# Minimal PyTorch Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvwPL6u83aNe"
   },
   "source": [
    "This notebooks shows a very minimal example on how to use PyTorch for training a neural network on the Iris data set.\n",
    "\n",
    "Note: This notebook is inspired by https://jamesmccaffrey.wordpress.com/2020/05/22/a-minimal-pytorch-complete-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhdvnPe4Q-pO"
   },
   "source": [
    "### 0. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K8-YOrlu3w8z"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-318dc571c01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf59x5HX3zMO"
   },
   "source": [
    "The following lines checks for GPU availability on the machine and sets the GPU as processing device (if available).\n",
    "If you are on Colab you can enable GPU support in the menu via  \"Runtime > Change runtime type\" and select \"GPU\" as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3DgoJj735Gr",
    "outputId": "237e74c2-d010-43d4-d5c2-12e699e8737b"
   },
   "outputs": [],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "  processing_chip = \"cuda:0\"\n",
    "  print(f\"{torch.cuda.get_device_name(0)} available\")\n",
    "else:\n",
    "  processing_chip = \"cpu\"\n",
    "  print(\"No GPU available\")\n",
    "\n",
    "device = torch.device(processing_chip)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8EgmXccAr9b"
   },
   "source": [
    "### 1. Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQbkjF8hstMZ"
   },
   "source": [
    "For this small example we use the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on these four features, we want to train a model that can predict the species.\n",
    "\n",
    "In the first step we load the data into a Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "DZoYUZfQ_TU8",
    "outputId": "99015012-d895-4d45-fdd0-477edcf22019"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/pabair/rl-course-ws2020/main/data/iris.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wk_OnO451DX"
   },
   "source": [
    "To be able to train a model, we first need to transform the *species* column into a numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "fQqdZZ16AHBe",
    "outputId": "155138d4-b609-47b1-d9fa-12e59ebbf101"
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset.species=='Iris-setosa', 'species'] = 0\n",
    "dataset.loc[dataset.species=='Iris-versicolor', 'species'] = 1\n",
    "dataset.loc[dataset.species=='Iris-virginica', 'species'] = 2\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYLgEfDUPu2_"
   },
   "source": [
    "Next, we specify which columns we want to use as features and which as label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uHB8hU0A4sI"
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[0:4]].values\n",
    "y = dataset.species.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNUlUKPYtz8C"
   },
   "source": [
    "We then split our data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQvkW7kct2Ry",
    "outputId": "a40538f1-f053-41e4-a11a-f2564b4cd230"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Ep6AWT5-Wy"
   },
   "source": [
    "To be able to use the data in PyTorch, we need to convert them into PyTorch tensors. Such a tensor can be thought of an efficient way to represent lists and matrices (similar to Numpy), with the additional benefit that they can be moved to the GPU (the `.to(device)` part in the code below) and that they support automatic backpropagation (more on this later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OI44o3i-grB"
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_X).float().to(device)\n",
    "test_x = torch.Tensor(test_X).float().to(device)\n",
    "train_y =torch.Tensor(train_y).long().to(device)\n",
    "test_y = torch.Tensor(test_y).long().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wcTXnyu7NWK"
   },
   "source": [
    "### 2. Model definition\n",
    "We define now the strucutre of our neural network.\n",
    "By convention we put in the `__init__` method the layers we want to use in the network and in the `forward` mehtod how data flows through this network.\n",
    "\n",
    "Our network has 4 input features, 7 hidden layer nodes and 3 output neurons. The hidden layer uses a Relu activation function. Note that the output layer dos not have a softmax activation, but rather gives out a raw score for each class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_W47oZ534E-1"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hidden = nn.Linear(4, 7)  \n",
    "    self.output = nn.Linear(7, 3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = F.relu(self.hidden(x))\n",
    "    z = self.output(z)  # no softmax. see CrossEntropyLoss() \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJyy5JG_84vs"
   },
   "source": [
    "### 3. Model Training\n",
    "We can now start traininging our network. We run several epochs in which we first predict on the training data with our network and than backpropagate the loss. For this we use PyTorch's build-in optimizer that runs gradient descent on the weights of the network. Hence, in every episode we reduce the loss on the training data and improve our network.\n",
    "\n",
    "As loss function we use cross entropy, which consumes the raw scores from the prediction and internally applies a softmax (that is why we do not need the softmax as last layer in the network).\n",
    "\n",
    "Note that all training data is passed at once to our network (line `net(train_x)`), since PyTorch will predict on all data points in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RQHZvvyAFzV",
    "outputId": "2b547d37-3b71-4b1f-8e6a-50e69d0d2a7d"
   },
   "outputs": [],
   "source": [
    "# create network, move it to device and set it to training-mode\n",
    "net = Net().to(device)\n",
    "net.train()\n",
    "\n",
    "# define the parameters for training\n",
    "no_epochs = 100\n",
    "learning_rate = 0.04\n",
    "loss_func = nn.CrossEntropyLoss()  # applies softmax() internally\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nStarting training \")\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(0, no_epochs):\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  output = net(train_x)\n",
    "\n",
    "  loss = loss_func(output, train_y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  train_losses.append(loss.item())\n",
    "  \n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Loss in epoch {epoch} is {loss.item()}\")\n",
    "\n",
    "print(\"Done training \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "fMPxG1i873W7",
    "outputId": "5d551446-3235-48e3-c45b-f0eececf763a"
   },
   "outputs": [],
   "source": [
    "  fig = plt.figure()\n",
    "  plt.plot(range(0, no_epochs), train_losses, color='blue')\n",
    "  plt.legend(['Train Loss'], loc='upper right')\n",
    "  plt.xlabel('number of epochs')\n",
    "  plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN8btFSP3yU2"
   },
   "source": [
    "### 4. Model Evaluation\n",
    "Finally, we check the model accuracy on the test data. For this we predict on the test data, identify the class with the highest score and compare it to the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsmVfo49Kytp",
    "outputId": "0659c70b-22cd-4ea2-b81f-221db140fdf2"
   },
   "outputs": [],
   "source": [
    "net.eval() # set network to evaluation mode\n",
    "y_pred = net(test_x)\n",
    "_, predicted = torch.max(y_pred.data, 1)\n",
    "correct = (predicted == test_y).sum().item()\n",
    "print(f\"Accuarcy is {100. * correct / len(test_x)}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMS3a9VIGYE8gp8KPG6Vfus",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "4_PyTorch_Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
